{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to modify `KNNClassifier` class from your practice in class. The `KNNClassifier` class with empty methods is provided below. Please, modify it to do all tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "class KNNClassifier(object):\n",
    "    \"\"\"\n",
    "    Omg, this code is horrible...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_dist=1., use_kd_tree=False, use_weights=False):\n",
    "        \"\"\"\n",
    "        This is a constructor of the class. \n",
    "        Here you can define parameters (max_dist) of the class and \n",
    "        attributes, that are visible within all methods of the class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        max_dist : float\n",
    "            Maximum distance between an object and its neighbors.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Make this parameter visible in all methods of the class\n",
    "        self.max_dist = max_dist\n",
    "        self.use_kd_tree = use_kd_tree\n",
    "        self.use_weights = use_weights\n",
    "        \n",
    "        self.kd_tree = None\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This method trains the KNN classifier. \n",
    "        Actualy, the KNN classifier has no training procedure.\n",
    "        It just remembers data (X, y) that will be used for predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "        y : numpy.array, shape = (n_objects)\n",
    "            1D array with the object labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### Your code here\n",
    "        \n",
    "        self.x_train = X\n",
    "        self.y_train = y\n",
    "        if self.use_kd_tree:\n",
    "            self.kd_tree = KDTree(self.x_train, leaf_size=30)\n",
    "    \n",
    "    def calculate_distances(self, X, one_x):\n",
    "        \"\"\"\n",
    "        This method calculates distances between one object and all other objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "        one_x : numpy.array, shape = (n_features)\n",
    "        \"\"\"\n",
    "        \n",
    "        dists = np.sqrt( np.sum( (X - one_x)**2, axis=1 ) )\n",
    "        return dists\n",
    "    \n",
    "    def _calculate_weight_for_point(self, x, x_pred):\n",
    "        return 1 / ((x[0] - x_pred[0]) ** 2 + (x[1] - x_pred[1]) ** 2) ** 0.5\n",
    "    \n",
    "    def _is_in_radius(self, x, check):\n",
    "        \"\"\"\n",
    "        This method checks, whether check is within x radius or not\n",
    "        x : numpy.array, shape = (2)\n",
    "        check : numpy.array, shape = (2)\n",
    "        \"\"\"\n",
    "        return (x[0] - check[0]) ** 2 + (x[1] - check[1]) ** 2 < self.max_dist ** 2\n",
    "    \n",
    "    def _get_closest_point(self, x):\n",
    "        \"\"\"\n",
    "        This method gets a point as an input and return index of a closest point to it.\n",
    "        x : numpy.array, shape = (2)\n",
    "        returns:\n",
    "        index: int\n",
    "        \"\"\"\n",
    "        distances = self.calculate_distances(self.x_train, x)\n",
    "        return np.argmin(distances)\n",
    "        \n",
    "    \n",
    "    def _get_closest_neighbours(self, x):\n",
    "        \"\"\"\n",
    "        This method gets a point as an input and returns indeces for features and labels of closest dots.\n",
    "        x : numpy.array, shape = (2)\n",
    "        \"\"\"\n",
    "        indxs = []\n",
    "        for i in range(len(self.x_train)):\n",
    "            if self._is_in_radius(x, self.x_train[i]):\n",
    "                indxs.append(i)\n",
    "        # This means that there is no point in our radius and we need to find closest.\n",
    "        if len(indxs) == 0:\n",
    "            indxs.append(self._get_closest_point(x))\n",
    "        return indxs\n",
    "    \n",
    "    def _predict_for_x(self, x):\n",
    "        \"\"\"\n",
    "        This method gets an x and returns predicted label y\n",
    "        \"\"\"\n",
    "        indxs = self._get_closest_neighbours(x)\n",
    "        labels = Counter()\n",
    "        # here we decide, which type of weights to use\n",
    "        if self.use_weights:\n",
    "            # Here we will have array of tuples, each tuple will be (weight, label)\n",
    "            weights = [(self._calculate_weight_for_point(x, self.x_train[index]), self.y_train[index]) for index in indxs]\n",
    "            for weight in weights:\n",
    "                labels[weight[1]] += weight[0]\n",
    "        else:\n",
    "            labels.update(Counter([self.y_train[i] for i in indxs]))\n",
    "        # This function returns list of tuples, that's why we need such magic in order to get most_common class\n",
    "        return labels.most_common(1)[0][0]\n",
    "    \n",
    "    def _predict_for_x_with_kd_tree(self, X):\n",
    "        \"\"\"\n",
    "        This method just use kd tree instead my own shitty implementation\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        indxs = self.kd_tree.query_radius(X, self.max_dist)\n",
    "        k_means_indxs = self.kd_tree.query(X)\n",
    "        for i, indx in enumerate(indxs):\n",
    "            # That means that there is some points in the radius\n",
    "            if len(indx) > 0:\n",
    "                labels = Counter()\n",
    "                if self.use_weights:\n",
    "                    weights = [(self._calculate_weight_for_point(X[i], self.x_train[j]), self.y_train[j]) for j in indx]\n",
    "                    for weight in weights:\n",
    "                        labels[weight[1]] += weight[0]\n",
    "                else:\n",
    "                    labels.update(Counter([self.y_train[j] for j in indx]))\n",
    "                y_pred.append(labels.most_common(1)[0][0])\n",
    "            else:\n",
    "                label = self.y_train[k_means_indxs[i][0]]\n",
    "                y_pred.append(label)\n",
    "        return y_pred\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs labels prediction for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted : numpy.array, shape = (n_objects)\n",
    "            1D array with predicted labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create an empty list for predicted labels\n",
    "        y_predicted = []\n",
    "        if self.use_kd_tree:\n",
    "            y_predicted = self._predict_for_x_with_kd_tree(X)\n",
    "        else:\n",
    "        ### Replace this line with your code:\n",
    "            for x in X:\n",
    "                y_predicted.append(self._predict_for_x(x))\n",
    "        \n",
    "        ### The end of your code\n",
    "            \n",
    "        return np.array(y_predicted) # return numpy.array\n",
    "    \n",
    "    \n",
    "    def predict_proba_for_point(self, x):\n",
    "        \"\"\"\n",
    "        This methods performs prediction of probabilites of each class for new object.\n",
    "        \"\"\"\n",
    "        kd_indxs = self.kd_tree.query_radius(np.array([x]), self.max_dist)\n",
    "        neighbours = self._get_closest_neighbours(x)\n",
    "        weights = {i:0 for i in range(max(self.y_train) + 1)}\n",
    "        if self.use_kd_tree:\n",
    "            # Since we won't to give full proba for point, we need to take care of classes, which are not in radius also.\n",
    "\n",
    "            if self.use_weights:\n",
    "                w = [(self._calculate_weight_for_point(x, self.x_train[i]), self.y_train[i]) for i in kd_indxs[0]]\n",
    "                for item in w:\n",
    "                    weights[item[1]] += item[0]\n",
    "            else:\n",
    "                for i in kd_indxs[0]:\n",
    "                    weights[self.y_train[i]] += 1\n",
    "        else:\n",
    "            if self.use_weights:\n",
    "                w = [(self._calculate_weight_for_point(x, self.x_train[index]), self.y_train[index]) for index in neighbours]\n",
    "                for item in w:\n",
    "                    item[weight[1]] += item[0]\n",
    "            else:\n",
    "                for i in neighbours:\n",
    "                    weights[self.y_train[i]] += 1\n",
    "        proba = [weights[item] / sum(weights.values()) for item in sorted(weights.keys())]\n",
    "        return proba\n",
    "                \n",
    "\n",
    "                    \n",
    "                \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs prediction of probabilities of each class for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted_proba : numpy.array, shape = (n_objects, n_classes)\n",
    "            2D array with predicted probabilities of each class. \n",
    "            Example:\n",
    "                y_predicted_proba = [[0.1, 0.9],\n",
    "                                     [0.8, 0.2], \n",
    "                                     [0.0, 1.0], \n",
    "                                     ...]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create an empty list for predictions\n",
    "        y_predicted_proba = []\n",
    "        \n",
    "        ### Replace these lines with your code:\n",
    "        for x in X:\n",
    "            y_predicted_proba.append(self.predict_proba_for_point(x))\n",
    "        ### The end of your code\n",
    "            \n",
    "        return np.array(y_predicted_proba) # return numpy.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (1 point) <br/>\n",
    "Create a matrix of object features `X` and vector of labels `y` for N=1000 objects using `sklearn.datasets.make_moons()` function from scikit-learn library. Also, set up random state in the function `random_state=42` and `noise=0.2`. To open the function description use `Shift` + `Tab` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here\n",
    "from sklearn.datasets import make_moons\n",
    "N = 1000\n",
    "X, y = make_moons(n_samples=N, noise=0.2, random_state=42)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[-0.112,  0.52 ],\n",
    "                [ 1.143, -0.343]])\n",
    "assert np.array_equal(np.round(X[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (1 point) <br/>\n",
    "\n",
    "Split the sample into train and test samples using `sklearn.model_selection.train_test_split()` function from scikit-learn library. Use `random_state = 42` and `test_size = 0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[ 0.77 , -0.289],\n",
    "                [ 0.239,  1.041]])\n",
    "assert np.array_equal(np.round(X_train[:2], 3), ans), ('Check your solution.')\n",
    "max(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 points) <br/>\n",
    "\n",
    "Modify class `KNNClassifier` above and implement `predict()` method that uses **max_dist** parameter to select neighbors like it's shown in the second figure (radius search). If there is no any object within **max_dist**, make decision based on the closest neighbor.\n",
    "\n",
    "<img src=\"img/knn2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 696 ms, sys: 7.97 ms, total: 704 ms\n",
      "Wall time: 717 ms\n",
      "Test accuracy of KNN classifier:  0.964\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.964, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (2 points) <br/>\n",
    "\n",
    "There are an algorithm [kd-tree](https://en.wikipedia.org/wiki/K-d_tree) that helps to find neighbors faster. Using [scipy.spatial.cKDTree](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.cKDTree.html#scipy.spatial.cKDTree) function modify you classifier to speed up **predict** method. Use `leafsize=30` in `KDTree`. Similar to `max_dist` option, add option `use_kd_tree = True/False` to your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.3 ms, sys: 10.3 ms, total: 59.5 ms\n",
      "Wall time: 73.2 ms\n",
      "Test accuracy of KNN classifier:  0.964\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.964, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (3 points) <br/>\n",
    "\n",
    "Now modify the **predict** method to provide prediction with neighbors weights.\n",
    "\n",
    "<img src=\"img/wv1.png\">\n",
    "\n",
    "<img src=\"img/wv2.png\">\n",
    "\n",
    "We propose you to use the following weights:\n",
    "\n",
    "$$\n",
    "w_{i} = \\frac{1}{\\rho(x, x_{i})}\n",
    "$$\n",
    "\n",
    "Similar to `max_dist` option, add option `use_weights = True/False` to your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 175 ms, sys: 4.25 ms, total: 180 ms\n",
      "Wall time: 189 ms\n",
      "Test accuracy of KNN classifier:  0.968\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True, use_weights=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.968, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (3 points) <br/>\n",
    "\n",
    "Develop **predict_proba** method of the classifier. For each object this method returns probability that the object belongs to each of the classes. \n",
    "\n",
    "For each object $x$ probability for each class is defined as:\n",
    "\n",
    "$$\n",
    "p_{c}(x) = \\frac{g_{c}(x)}{\\sum_{i=1}^{C} g_{i}(x)}\n",
    "$$\n",
    "\n",
    "where $C$ is number of classes.\n",
    "\n",
    "Then, the object has a vector of probabilities:\n",
    "\n",
    "$$\n",
    "p(x) = (p_{1}(x), p_{2}(x), ..., p_{C}(x))\n",
    "$$\n",
    "\n",
    "Use neighbors weights as in Task 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 923 ms, sys: 7.47 ms, total: 931 ms\n",
      "Wall time: 964 ms\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True, use_weights=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict_proba = knn.predict_proba(X_test) # measure time for prediction\n",
    "\n",
    "# Example of the output\n",
    "y_test_predict_proba[:10, :] # the first 10 rows\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[0.046, 0.954],\n",
    "                [0.962, 0.038]])\n",
    "assert np.array_equal(np.round(y_test_predict_proba[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
