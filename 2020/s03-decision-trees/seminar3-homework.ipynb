{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework your task will be to modify `DecisionTreeClassifier` class from your practice in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (0.5 points) <br/>\n",
    "\n",
    "Download Telecom Data To Analyse The Churn Data Set `telecom_churn.csv`. Read it using `pandas.read_csv()` function. To open the function description use `Shift` + `Tab` . Show the first 5 rows of the dataset using `pandas.DataFrame.head()` function.\n",
    "\n",
    "[Dataset Information](https://www.kaggle.com/spscientist/telecom-data/download):\n",
    "\n",
    "Columns:\n",
    "* state (State letter code)\n",
    "* account length (How long the client has been served by the company)\n",
    "* area code (Phone number prefix)\n",
    "* phone number\n",
    "* international plan (International roaming (connected / not connected))\n",
    "* voice mail plan (Voice mail (connected / not connected))\n",
    "* number vmail messages (Number of voice messages)\n",
    "* total day minutes (Total duration of conversations during the day)\n",
    "* total day calls (Total calls during the day)\n",
    "* total day charge (Total amount of payment for services during the day)\n",
    "* total eve minutes (Total duration of conversations in the evening)\n",
    "* total eve calls (Total number of calls in the evening)\n",
    "* total eve charge (Total amount of payment for services in the evening)\n",
    "* total night minutes (Total duration of conversations at night)\n",
    "* total night calls (Total number of calls at night)\n",
    "* total night charge (Total amount of payment for services at night)\n",
    "* total intl minutes (Total duration of international calls)\n",
    "* total intl calls (Total number of international call)\n",
    "* total intl charge (Total payment for international calls)\n",
    "* customer service calls (The number of calls to the service center)\n",
    "* churn\n",
    "\n",
    "Churn is target: True - client has left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which features are categorical? \n",
    "* Which features can be considered as object ID? Should we keep them? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (0.5 points) <br/>\n",
    "\n",
    "The target column for classification is `Churn`. However, it is categorical feature, so you need to encode this by `0` and `1` values (False = 0, True = 1). Implement this mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix `X` and vector of labels `y`. Split them into train and test samples using `sklearn.model_selection.train_test_split()` function from scikit-learn library. Also, set up random state in the function `random_state=42`.\n",
    "\n",
    "Expected output dataframes names: `df_X_train`, `df_X_test` и `y_train`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your result\n",
    "assert(round(df_X_test.size/X.size, 1)==0.2)\n",
    "assert(round(y_test.size/y.size, 1)==0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 points) categorical feature encoding\n",
    "\n",
    "Use (0, 1) for binary features. Replace values both for `df_X_train` and `df_X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement target encoding for other categorical features. For this task we propose you to implement the simpliest form of target encoding, which goes as following:\n",
    "\n",
    "Training:\n",
    "* Consider categorical feature $f$\n",
    "* For each category $c$ in this feature calculate mean value of target feature $y$: $v_c$\n",
    "\n",
    "Application:\n",
    "* Consider feature $f$\n",
    "* Replace each category $c$ with $v_c$\n",
    "* If $v_c$ is not calculated (possible new category) - replace $c$ with global target mean\n",
    "\n",
    "Create the next funсtions:\n",
    "* `learn_target_encoding `\n",
    "    * Input: train dataframe, target array, list of features names for encoding\n",
    "    * Output: nested dict with mapping from category to target encoded value for each categorical feature, global target mean value\n",
    "* `apply_target_encoding`\n",
    "    * Input: dataframe, encoding_dict\n",
    "    * Output: transformed dataframe in form of numpy array\n",
    "\n",
    "HINT for pandas:\n",
    "* `df.groupby(..)`\n",
    "* `df.column.to_dict(..)`\n",
    "* `df.column.replace(some_dict)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_target_encoding(df_input, y_input, features2encode):    \n",
    "    encoding_dict = {}\n",
    "    # Your code here\n",
    "    \n",
    "    return encoding_dict, target_mean\n",
    "\n",
    "def apply_target_encoding(df_input, encoding_dict, global_target_mean):    \n",
    "    # Your code here\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your functions:\n",
    "input_df = pd.read_csv(\"task4_train_only_for_check.csv\", sep=\"\\t\")\n",
    "features_list = ['cat2']\n",
    "\n",
    "X_dataframe = input_df[features_list]\n",
    "y_array = input_df['y']\n",
    "test_dataframe = pd.read_csv(\"task4_test_only_for_check.csv\", sep=\"\\t\")\n",
    "\n",
    "dictionary, glob_mean = learn_target_encoding(X_dataframe, y_array, features_list)\n",
    "output_matrix = apply_target_encoding(test_dataframe, dictionary, glob_mean)\n",
    "\n",
    "assert(np.array_equal(output_matrix, np.array([[0, 0, 0, 1, 1, 0], [3, 3, 5, 4, 2, 3.076923076923077]]).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (1 point) <br/>\n",
    "\n",
    "Now let's look at this data. For each input feature plot historgrams, as it was done in you practice in class. How do you think, what features are the most informative? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (1 point) <br/>\n",
    "\n",
    "Fit `DecisionTreeClassifier` from you practice in class with this sample. Find the best parameters. What is `accuracy` of the classification on the test sample?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (3 points) <br/>\n",
    "\n",
    "Implement feature importance estimation in `DecisionTreeClassifier`. Importance of a feature $f$ is defined as follows:\n",
    "\n",
    "* Let $T(f)$ be the set of all nodes, relying on feature $f$ when making split.\n",
    "* Efficiency of split at node $t$: $\\Delta I(t)=I(t)-\\sum_{c\\in childen(t)}\\frac{n_{c}}{n_{t}}I(c)$,  where $n_t$, $n_c$ is number of samples in nodes t, c\n",
    "* Feature importance of $f$: $\\sum_{t\\in T(f)}n_{t}\\Delta I(t)$, where $n_t$ is number of samples in node t\n",
    "\n",
    "Calculate importance of input features in your dataset. What features are the most important (informative) for the classification?\n",
    "\n",
    "To do this you have to update your decision_tree learning procedure:\n",
    "* Return best_information_gain from best_split\n",
    "* Save best_information_gain in node\n",
    "* Traverse tree recursively and caclulate feature importance for every feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Output: array 'features_order' from highest to lowest importance (first 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(features_order)==5)\n",
    "assert(np.array_equal(features_order, np.array(['total day charge', 'customer service calls', 'international plan', 'total intl calls', 'total eve charge'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (2 points) <br/>\n",
    "\n",
    "Implement Reduced Error Pruning in you `DecisionTreeClassifier`. \n",
    "\n",
    "Fit the classifier similar to **Task 6** setting up `max_depth=20`. \n",
    "\n",
    "Prune this decision tree using train data. \n",
    "\n",
    "Create a plot \"Accuracy (y-axis) vs Numbers of vertices (x-axis)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "449.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
